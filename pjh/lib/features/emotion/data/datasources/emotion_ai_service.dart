import 'dart:convert';
import 'dart:developer' as dev;
import 'dart:io';
import 'dart:math';

import 'package:supabase_flutter/supabase_flutter.dart';
import '../../../../config/api_config.dart';
import '../../../../core/error/exceptions.dart';
import '../models/emotion_analysis_model.dart';
import '../services/gemini_ai_service.dart';

abstract class EmotionAIService {
  Future<EmotionScoresModel> analyzeEmotionFromImage(File imageFile);
}

class EmotionAIServiceImpl implements EmotionAIService {
  late final GeminiAIService _geminiService;
  final SupabaseClient _supabase = Supabase.instance.client;

  EmotionAIServiceImpl() {
    _geminiService = GeminiAIService();
  }

  @override
  Future<EmotionScoresModel> analyzeEmotionFromImage(File imageFile) async {
    try {
      // Supabase Edge Functionì„ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©
      if (_supabase.auth.currentUser != null) {
        dev.log('ğŸ”µ [1ì°¨ ì‹œë„] Supabase Edge Functionìœ¼ë¡œ ê°ì • ë¶„ì„ ì‹œì‘', name: 'EmotionAIService');
        return await _analyzeWithSupabaseEdgeFunction(imageFile);
      }

      // Gemini API ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ì‹¤ì œ AI ë¶„ì„ ìˆ˜í–‰
      if (ApiConfig.isGeminiConfigured) {
        dev.log('ğŸŸ¢ [2ì°¨ ì‹œë„] Google Gemini APIë¡œ ê°ì • ë¶„ì„ ì‹œì‘', name: 'EmotionAIService');
        dev.log('   API ì—”ë“œí¬ì¸íŠ¸: https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent', name: 'EmotionAIService');
        return await _geminiService.analyzeEmotionFromImage(imageFile);
      }

      // ìµœí›„ ìˆ˜ë‹¨ìœ¼ë¡œ ë°ëª¨ ëª¨ë“œ
      dev.log('ğŸŸ¡ [3ì°¨ ì‹œë„] ë°ëª¨ ëª¨ë“œë¡œ ê°ì • ë¶„ì„ (ëœë¤ ê²°ê³¼ ìƒì„±)', name: 'EmotionAIService');
      return await _fallbackAnalysis(imageFile);

    } catch (e) {
      if (e is ImageException || e is AnalysisException) {
        rethrow;
      }

      // ì˜¤ë¥˜ ì‹œ ë°ëª¨ ëª¨ë“œë¡œ fallback
      dev.log('ğŸ”´ AI ë¶„ì„ ì˜¤ë¥˜, ë°ëª¨ ëª¨ë“œë¡œ ì „í™˜: ${e.toString()}', name: 'EmotionAIService.fallback');
      return await _fallbackAnalysis(imageFile);
    }
  }

  Future<EmotionScoresModel> _analyzeWithSupabaseEdgeFunction(File imageFile) async {
    try {
      // ì´ë¯¸ì§€ë¥¼ base64ë¡œ ë³€í™˜
      final bytes = await imageFile.readAsBytes();
      final base64Image = base64Encode(bytes);

      final user = _supabase.auth.currentUser!;

      // Supabase Edge Function í˜¸ì¶œ
      final response = await _supabase.functions.invoke(
        'analyze-emotion',
        body: {
          'imageBase64': base64Image,
          'userId': user.id,
        },
      );

      if (response.data['success'] == true) {
        final emotionData = response.data['data']['emotion_analysis'];
        return EmotionScoresModel.fromMap(emotionData);
      } else {
        throw AnalysisException(response.data['error'] ?? 'Edge Function í˜¸ì¶œ ì‹¤íŒ¨');
      }
    } catch (e) {
      dev.log('Supabase Edge Function ì˜¤ë¥˜: $e', name: 'EmotionAIService.edgeFunction');
      rethrow;
    }
  }

  Future<EmotionScoresModel> _fallbackAnalysis(File imageFile) async {
    // ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if (!await imageFile.exists()) {
      throw const ImageException('ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
    }

    // íŒŒì¼ í¬ê¸° í™•ì¸ (5MB ì œí•œ)
    final fileSize = await imageFile.length();
    if (fileSize > 5 * 1024 * 1024) {
      throw const ImageException('ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. (ìµœëŒ€ 5MB)');
    }

    // AI ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜ (2-3ì´ˆ ëŒ€ê¸°)
    await Future.delayed(const Duration(seconds: 2));

    // ë°ëª¨ìš© ëœë¤ ê°ì • ì ìˆ˜ ìƒì„±
    final random = Random();

    // í•©ì´ 1.0ì´ ë˜ë„ë¡ ëœë¤ ê°ì • ì ìˆ˜ ìƒì„±
    final values = List.generate(5, (index) => random.nextDouble());
    final sum = values.reduce((a, b) => a + b);
    final normalizedValues = values.map((v) => v / sum).toList();

    return EmotionScoresModel(
      happiness: normalizedValues[0],
      sadness: normalizedValues[1],
      anxiety: normalizedValues[2],
      sleepiness: normalizedValues[3],
      curiosity: normalizedValues[4],
    );
  }

}